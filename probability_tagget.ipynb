{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "probability_tagget.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_IldSEFdZL_",
        "colab_type": "text"
      },
      "source": [
        "#Тегирование с помощью pymrphy2 и вероятностной модели снятия омонимии\n",
        "@Василий Гурьев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Bjk1da5uIM",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gldbpil03is4",
        "colab_type": "code",
        "outputId": "d207efeb-c157-4bf1-857e-c2f87435a436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "!pip install pymorphy2[fast]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ef/91b619a399685f7a0a95a03628006ba814d96293bbbbed234ee66fbdefd9/DAWG-0.8.0.tar.gz (371kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 45.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.8.0-cp36-cp36m-linux_x86_64.whl size=859192 sha256=efce2c0a92a9ab12c008a665e1419867b4863197f99d754d900020f053ea9da2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/1f/f0/a5b1f9d02e193c997d252c33d215f24dfd7a448bc0166b2a12\n",
            "Successfully built DAWG\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.8.0 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B2WLz1y5e36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pymorphy2 # морфологический анализатор\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39gw73BU5xgY",
        "colab_type": "text"
      },
      "source": [
        "#Defs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeZjH7LZtn3q",
        "colab_type": "text"
      },
      "source": [
        "##text_to_sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s_0g_lutXp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_sentences(text): # режем текст на предложения\n",
        "  return re.findall(r'[\"А-ЯЁA-Z].+?(?:[\"a-zа-яё]{2}|[\"A-ZА-ЯЁ]{2})(?:\\.+|\\!+|\\?+)', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKO31jRG0747",
        "colab_type": "text"
      },
      "source": [
        "##sentence_to_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1JS7ClW1B2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_to_words(sentence): # режем предложения на слова\n",
        "  return re.findall(r'[A-Za-zА-ЯЁа-яё0-9-]+', sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdMzz2Ccx1Nk",
        "colab_type": "text"
      },
      "source": [
        "##words_to_tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNyplhtnzmIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def words_to_tags(words): # определение тегов слов в предложении\n",
        "  tags = Dehomonym() # сниматель омонимии\n",
        "  for word in words: # последовательно добавляем слова в обработку\n",
        "    tags.add(word)\n",
        "  tags.end() # добавляем токен окончания предложения\n",
        "  return tags.paths # возвращаем цепочку тегов"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hdW9uqEILgy",
        "colab_type": "text"
      },
      "source": [
        "##Dehomonym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mU9-dKjIXw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dehomonym(): # класс для снятия омонимии\n",
        "\n",
        "  def __init__(self):\n",
        "    self.tags = [['START']] # тег начала предложения\n",
        "    self.scores = [1] # вероятностная оценка тега начала предложения \n",
        "    # расчитывается перемножением вероятностей тегов из pymorphy2 с частотой их совместной встречаемости\n",
        "    self.paths = [['START']] # начало цепочки тегов\n",
        "    self.k_score = 1e+3 # коэффициент для замедления роста оценки с увеличением длины предложения\n",
        "    self.on = True # снятие омонимии включено\n",
        "    \n",
        "\n",
        "  def word_to_parse(self, word): # получение списка вариантов морфологического анализа для слова\n",
        "    if word not in parsed: # проверяем есть ли слово в обработанных\n",
        "      parsed[word] = morph.parse(word) # получаем список вариантов морфологических анализа (объектов Parse)\n",
        "    return parsed[word] # возвращаем список объектов Parse\n",
        "\n",
        "\n",
        "  def get_occurrence(self, tag, new_tag): # получение частоты последовательности тегов\n",
        "    '''\n",
        "    тег - это список граммем; т.о. частота последовательности тегов - это минимальная\n",
        "    частота последовательности граммем из данных тегов\n",
        "    '''\n",
        "    return min([dispositions.loc[left, right][0] for right in new_tag for left in tag])\n",
        "\n",
        "\n",
        "  def add(self, word): # добавление вариантов тегов данного токена\n",
        "    if self.on:\n",
        "      parses = self.word_to_parse(word) # получаем список вариантов морфологического анализа для данного токена\n",
        "      new_tags = [[grammeme for grammeme in grammemes if grammeme in parse.tag] for parse in parses]\n",
        "      # извлекаем теги из объектов Parse и упаковываем их в список списков\n",
        "      n = len(new_tags) # определяем количество вариантов анализа\n",
        "      if len(new_tags[0]): # если результат анализа не пуст\n",
        "        new_scores = [0] * n # создаём список вероятностных оценок\n",
        "        new_paths = [[new_tags[i]] for i in range(n)] # создаём список вариантов окончаний цепочки\n",
        "        for right, new_tag in enumerate(new_tags): # перебираем варианты тегов данного токена\n",
        "          for left, tag in enumerate(self.tags): # перебираем вариенты тегов предыдущег токена\n",
        "            score = self.scores[left] * parses[right].score * self.get_occurrence(tag, new_tag) / self.k_score\n",
        "            # считатем оценку, перемножая оценку предыдущего тега, вероятность данного и частоту их встречаемости\n",
        "            if score >= new_scores[right]: # если оценка больше предыдущей\n",
        "              new_scores[right] = score # обновляем её\n",
        "              path = self.paths[left] # и запоминаем цепочку, конец которой имеет максимальную оценку\n",
        "          new_paths[right].extend(path) # добавляем её к вариантам тегов данного токена\n",
        "        self.tags = new_tags # обновляем список вариантов тегов последнего токена\n",
        "        self.scores = new_scores # обновляем список оценок вариантов тегов\n",
        "        self.paths = new_paths # обновляем цепочки тегов\n",
        "      else:\n",
        "        self.on = False\n",
        "        self.tags = None\n",
        "        self.scores = None\n",
        "        self.paths = None\n",
        "\n",
        "\n",
        "  def end(self): # конец предложения\n",
        "    if self.on:\n",
        "      new_score = 0 # начаотная оценка конца предложения\n",
        "      new_paths = [['END']] # сепочка с токеном конца предложения\n",
        "      for left, tag in enumerate(self.tags): # перебираем вариенты тегов предыдущег токена\n",
        "        score = self.scores[left] * self.get_occurrence(tag, ['END']) / self.k_score\n",
        "        # считатем оценку\n",
        "        if score >= new_score: # если оценка больше предыдущей\n",
        "          new_score = score # обновляем её\n",
        "          path = self.paths[left] # и запоминаем цепочку, конец которой имеет максимальную оценку\n",
        "      new_paths[0].extend(path) # добавляем её к тегу конечного токена\n",
        "      self.tags = [['END']] # обновляем список вариантов тегов последнего токена\n",
        "      self.scores = [new_score] # бновляем список оценок вариантов тегов\n",
        "      self.paths = [tag for tag in new_paths[0][-2:0:-1]] # разворачиваем цепочку, отбрасывая тег начального токена\n",
        "      self.on = False # отключаем возможность добавлять токены\n",
        "    # print(self.paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjj9hH_YrlKw",
        "colab_type": "text"
      },
      "source": [
        "#Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upAHTPNxwdGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer() # морфологический анализатор\n",
        "parsed = {} # словарь обработанных токенов"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YevsZ5Xerh-Q",
        "colab_type": "code",
        "outputId": "4766efe8-b372-4ced-e4cd-7aac63eeaacd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "drive.mount('/content/gdrive') # подключаем диск\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/NNDW') # задаём рабочую директорию"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-mDpDQj5Y8m",
        "colab_type": "code",
        "outputId": "7f80a32c-6cb0-4d1f-eafe-bfadde4c9521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "dispositions = pd.read_csv('dicts/dispositions.csv', index_col=[0, 1]) # загрузка частот последовательности граммем\n",
        "dispositions.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>occurrences</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Geox</th>\n",
              "      <th>END</th>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Supr</th>\n",
              "      <th>END</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Apro</th>\n",
              "      <th>END</th>\n",
              "      <td>5975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cmp2</th>\n",
              "      <th>END</th>\n",
              "      <td>392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Init</th>\n",
              "      <th>END</th>\n",
              "      <td>605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           occurrences\n",
              "start end             \n",
              "Geox  END           59\n",
              "Supr  END            0\n",
              "Apro  END         5975\n",
              "Cmp2  END          392\n",
              "Init  END          605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9AOtmfGIKXy4",
        "colab": {}
      },
      "source": [
        "grammemes = sorted(list(set(dispositions.index.get_level_values(0)) - {'START'})) # словарь граммем"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5b-u9Nt50bY",
        "colab_type": "text"
      },
      "source": [
        "#Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQNNb7RCevjb",
        "colab_type": "code",
        "outputId": "ccae8f30-31ea-4f51-dec5-70a0eb7c6185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for year in range(2002, 2003): # для каждого года (одного достаточно)\n",
        "  sentences = pd.DataFrame(columns=['sentence']) # создаём коллекцию предложений\n",
        "  data = pd.read_csv(f'data/newsru_{year}.csv', usecols=['text']) # загружаем данные\n",
        "  data.drop_duplicates(inplace=True) # удаляем дубли\n",
        "  data.text = data.text.apply(lambda s: re.sub(r'<p>|<s>|</p>|</s>', '', s)) # удаляем теги\n",
        "  for i, text in enumerate(data.text): # для каждого текста\n",
        "    print(year, i, end=' ') # печатаем год и номер текста\n",
        "    sentences = pd.concat(\n",
        "        [\n",
        "        sentences,\n",
        "        pd.DataFrame(text_to_sentences(text), columns=['sentence']) # режем текст на предложения\n",
        "        ], ignore_index=True\n",
        "        ) # и добавляем их в коллекцию предложений\n",
        "    # clear_output()\n",
        "  sentences.drop_duplicates(inplace=True) # удавляем дубли\n",
        "  sentences['words'] = sentences.sentence.apply(sentence_to_words) # получаем списки слов для каждого предложения\n",
        "  pd.DataFrame(columns=['tags', 'lemmas']).to_csv(f'data/tags_{year}.csv', index=False) # сохраняем будущую коллекцию тегов\n",
        "  sentences.to_csv(f'data/sentences_{year}.csv', index=False) # сохраняем коллекцию предложений\n",
        "\n",
        "\n",
        "for year in range(2002, 2003): # для каждого года\n",
        "  words = pd.read_csv(f'data/sentences_{year}.csv', usecols=['words']) # загружаем коллекцию предложений как списка слов\n",
        "  tags = pd.read_csv(f'data/tags_{year}.csv') # загружаем коллекцию тегов\n",
        "  while len(words) > len(tags): # пока не получены теги для всех слов\n",
        "    print(f'{year}: {len(tags)}/{len(words)}') # печатаем прогресс\n",
        "    tags.loc[len(tags), 'tags'] = words_to_tags(eval(words.loc[len(tags), 'words']))\n",
        "    # получаем список тегов из списка слов (который в Pandas хранится, как строка)\n",
        "\n",
        "    if not len(tags) % 1000:\n",
        "      tags.to_csv(f'data/tags_{year}.csv', index=False) # сохраняем промежуточный результат\n",
        "  tags.to_csv(f'data/tags_{year}.csv', index=False) # сохраняем коллекцию тегов"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/173402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EERFVTpTeEo",
        "colab_type": "code",
        "outputId": "660f106c-708d-4c67-e7b3-c06dbabd7832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "tags = pd.read_csv('data/tags_2002.csv') # изначально получал и леммы, но это накладно, и они не понадобятся\n",
        "tags.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tags</th>\n",
              "      <th>lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[['CONJ'], ['3per', 'VERB', 'impf', 'indc', 'p...</td>\n",
              "      <td>['как', 'сообщать', 'нтв', 'заокеанский', 'мед...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[['PREP'], ['ADJF', 'Apro', 'accs', 'neut', 's...</td>\n",
              "      <td>['по', 'их', 'слово', 'полезный', 'вещество', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[['NOUN', 'inan', 'masc', 'nomn', 'sing'], ['P...</td>\n",
              "      <td>['поход', 'в', 'сауна', 'как', 'средство', 'бо...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[['ADVB'], ['3per', 'NPRO', 'accs', 'masc', 's...</td>\n",
              "      <td>['там', 'он', 'иногда', 'называть', 'русский']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[['VERB', 'impr', 'intr', 'perf', 'plur'], ['3...</td>\n",
              "      <td>['запить', 'они', 'два', 'большой', 'стакан', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                tags                                             lemmas\n",
              "0  [['CONJ'], ['3per', 'VERB', 'impf', 'indc', 'p...  ['как', 'сообщать', 'нтв', 'заокеанский', 'мед...\n",
              "1  [['PREP'], ['ADJF', 'Apro', 'accs', 'neut', 's...  ['по', 'их', 'слово', 'полезный', 'вещество', ...\n",
              "2  [['NOUN', 'inan', 'masc', 'nomn', 'sing'], ['P...  ['поход', 'в', 'сауна', 'как', 'средство', 'бо...\n",
              "3  [['ADVB'], ['3per', 'NPRO', 'accs', 'masc', 's...     ['там', 'он', 'иногда', 'называть', 'русский']\n",
              "4  [['VERB', 'impr', 'intr', 'perf', 'plur'], ['3...  ['запить', 'они', 'два', 'большой', 'стакан', ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP6jmwC8UT1_",
        "colab_type": "code",
        "outputId": "295742b9-e16a-404c-f8c7-28cff949bb8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "tags.tags[0] # так выглядит список тегов"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[['CONJ'], ['3per', 'VERB', 'impf', 'indc', 'pres', 'sing', 'tran'], ['NOUN', 'inan', 'neut', 'nomn', 'sing'], ['ADJF', 'nomn', 'plur'], ['NOUN', 'anim', 'masc', 'nomn', 'plur'], ['3per', 'VERB', 'futr', 'indc', 'perf', 'plur', 'tran'], ['ADJF', 'Apro', 'datv', 'plur'], ['NOUN', 'anim', 'datv', 'masc', 'plur'], ['PRTF', 'actv', 'datv', 'past', 'perf', 'plur', 'tran'], ['PREP'], ['ADJF', 'ablt', 'masc', 'sing'], ['NOUN', 'ablt', 'inan', 'masc', 'sing'], ['INFN', 'perf', 'tran'], ['ADVB'], ['NOUN', 'accs', 'femn', 'inan', 'sing'], ['ADJF', 'gent', 'masc', 'sing'], ['NOUN', 'gent', 'inan', 'masc', 'sing']]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajp1Dv2QUhsE",
        "colab_type": "code",
        "outputId": "01ed3fac-e910-4426-bb21-e0cb0cfd9920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "texts = pd.read_csv(f'data/sentences_2002.csv') # а так коллекция предложений\n",
        "texts.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Как сообщает НТВ, заокеанские медики рекоменду...</td>\n",
              "      <td>['Как', 'сообщает', 'НТВ', 'заокеанские', 'мед...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>По их словам, полезные вещества в нем помогают...</td>\n",
              "      <td>['По', 'их', 'словам', 'полезные', 'вещества',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Поход в сауну как средство борьбы с похмельем ...</td>\n",
              "      <td>['Поход', 'в', 'сауну', 'как', 'средство', 'бо...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Там его иногда называют русским.</td>\n",
              "      <td>['Там', 'его', 'иногда', 'называют', 'русским']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Запейте их двумя большими стаканами воды.</td>\n",
              "      <td>['Запейте', 'их', 'двумя', 'большими', 'стакан...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence                                              words\n",
              "0  Как сообщает НТВ, заокеанские медики рекоменду...  ['Как', 'сообщает', 'НТВ', 'заокеанские', 'мед...\n",
              "1  По их словам, полезные вещества в нем помогают...  ['По', 'их', 'словам', 'полезные', 'вещества',...\n",
              "2  Поход в сауну как средство борьбы с похмельем ...  ['Поход', 'в', 'сауну', 'как', 'средство', 'бо...\n",
              "3                   Там его иногда называют русским.    ['Там', 'его', 'иногда', 'называют', 'русским']\n",
              "4          Запейте их двумя большими стаканами воды.  ['Запейте', 'их', 'двумя', 'большими', 'стакан..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}